{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4fff4c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a94330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd606a0",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f9f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pd.read_csv('Ads_CTR_Optimisation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92871a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad 1</th>\n",
       "      <th>Ad 2</th>\n",
       "      <th>Ad 3</th>\n",
       "      <th>Ad 4</th>\n",
       "      <th>Ad 5</th>\n",
       "      <th>Ad 6</th>\n",
       "      <th>Ad 7</th>\n",
       "      <th>Ad 8</th>\n",
       "      <th>Ad 9</th>\n",
       "      <th>Ad 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
       "0     1     0     0     0     1     0     0     0     1      0\n",
       "1     0     0     0     0     0     0     0     0     1      0\n",
       "2     0     0     0     0     0     0     0     0     0      0\n",
       "3     0     1     0     0     0     0     0     1     0      0\n",
       "4     0     0     0     0     0     0     0     0     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3eb68",
   "metadata": {},
   "source": [
    "### Random Policy\n",
    "If we were to not have Reinforcement Learning, we would place the ads randomly at given positions. We will now simulate the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d94e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards: 1229\n"
     ]
    }
   ],
   "source": [
    "reward = 0\n",
    "for x in range(len(env)):\n",
    "    action = np.random.randint(0,10)\n",
    "    if env.values[x][action]==1:\n",
    "        reward+=1\n",
    "print('rewards:', reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce264e0c",
   "metadata": {},
   "source": [
    "### Using Max Policy\n",
    "Another question we might ask: is it right to display the ad where it is clicked the most number of times. For instance, there might be a certain position where the ad clicked with a higher probability. Since the values of the rows is either 1 or 0, we can sum across the columns and count the number of times ad in the position was clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485a7af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count\n",
       "ad       \n",
       "1    1703\n",
       "2    1295\n",
       "3     728\n",
       "4    1196\n",
       "5    2695\n",
       "6     126\n",
       "7    1112\n",
       "8    2091\n",
       "9     952\n",
       "10    489"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicked_counts = env.values.sum(axis=0)\n",
    "counts = pd.DataFrame({'ad': np.arange(1,11), 'count': clicked_counts})\n",
    "counts.set_index('ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1849db",
   "metadata": {},
   "source": [
    "Which indicates Ad 5 was clicked 2695. So if we were to always place ad on position 5, it would be click around 2695 times. But can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226dd60",
   "metadata": {},
   "source": [
    "### Dynamic Programming (Policy Iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39138fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec0ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size=len(env)\n",
    "state_list=[]\n",
    "for state in range(state_size):\n",
    "    state_list.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b524b187",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m action \u001b[38;5;241m=\u001b[39m policy[state]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#print(action)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m new_state \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(state_list) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m([state])))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(new_state)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m reward \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mvalues[state][action]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# action could be placing the ad on any of the 10 positions\n",
    "action_space = np.arange(0, 10)\n",
    "\n",
    "policy = [random.choice(action_space) for x in range(state_size)]\n",
    "# will take random action for the first time\n",
    "first_time = True\n",
    "\n",
    "# delta\n",
    "small_change = 1e-20\n",
    "# discount factor\n",
    "gamma = 0.9\n",
    "episodes = 0\n",
    "max_episodes = 100\n",
    "\n",
    "V = dict()\n",
    "# last positions reward will be 1 - terminal state\n",
    "V[10000] = 1\n",
    "\n",
    "# initially the value function for all states will be random values close to zero\n",
    "for i in range(state_size):\n",
    "    V[i] = np.random.random()\n",
    "deltas = []\n",
    "while episodes < max_episodes:\n",
    "    # policy evaluation (until convergence of state value function)\n",
    "    while True:\n",
    "        if episodes > max_episodes:\n",
    "            break\n",
    "        episodes += 1\n",
    "        if episodes % 100 == 0:\n",
    "            print(\"Current episode: {}\".format(episodes))\n",
    "        biggest_change = 0\n",
    "        # loop through every state present\n",
    "        for state in range(state_size):\n",
    "            old_V = V[state]\n",
    "            # take random action according to policy\n",
    "            action = policy[state]\n",
    "            #print(action)\n",
    "            new_state = random.choice(list(set(state_list) - set([state])))\n",
    "            #print(new_state)\n",
    "            reward = env.values[state][action]\n",
    "            #\n",
    "            V[state] = (reward + gamma * V[new_state])/9999\n",
    "            # We're calculating biggest change to have an idea on convergence. \n",
    "            # Initially, the changes will be huge, but as \n",
    "            # we update the values, they will tend towards a convergence point\n",
    "            biggest_change = max(biggest_change, abs(V[state] - old_V))\n",
    "        deltas.append(biggest_change)\n",
    "        if biggest_change < small_change:\n",
    "            break\n",
    "            \n",
    "    # policy improvement\n",
    "    policy_changed = False\n",
    "    for state in range(state_size):\n",
    "        best_val = -np.inf\n",
    "        best_action = -1\n",
    "        for action in action_space:\n",
    "            new_state = random.choice(list(set(state_list) - set([state])))\n",
    "            reward = env.values[state][action]\n",
    "            # calculate the action with the best\n",
    "            # future reward\n",
    "            future_reward = (reward + gamma * V[new_state])/9999\n",
    "            if future_reward > best_val:\n",
    "                best_val = future_reward\n",
    "                best_action = action\n",
    "        assert best_action != -1\n",
    "        # After convergence, the policy will not change since we would have already reached\n",
    "        # the optimum policy. So check if the policy is not updated, if not then stop. \n",
    "        if policy[state] != best_action:\n",
    "            policy_changed = True\n",
    "        policy[state] = best_action\n",
    "\n",
    "    if not policy_changed:\n",
    "        break\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken in seconds: \", end-start)\n",
    "print(\"Total episodes trained: {}\".format(episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "plt.plot(deltas, label=\"deltas\")\n",
    "plt.legend()\n",
    "plt.title('Convergence plot: Policy iteration')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = 0\n",
    "for x in range(len(env)):\n",
    "    action = policy[x]\n",
    "    if env.values[x][action]==1:\n",
    "        reward+=1\n",
    "print('rewards:', reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b4d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
